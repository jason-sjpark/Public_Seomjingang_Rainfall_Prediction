{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "5_aI5U_a8nr1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# import package\n",
    "from __future__ import print_function, division\n",
    "# model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "#from torchsummary import summary\n",
    "from torch import optim\n",
    "\n",
    "# dataset and transformation\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import models, utils\n",
    "import os\n",
    "\n",
    "# display images\n",
    "from torchvision import utils\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# utils for writing own dataset\n",
    "import time\n",
    "import copy\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.ion()   # interactive mode\n",
    "\n",
    "IMG_SIZE  = (224,224) # image size of efficient net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yc4F5GMW9OkK",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 1. 데이터셋 불러오기\n",
    "데이터셋은 torchvision 패키지에서 제공하는 STL10 dataset을 이용하겠습니다. STL10 dataset은 10개의 label을 갖으며 train dataset 5000개, test dataset 8000개로 구성됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "10DyLx_7WCRQ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "WRITING CUSTOM DATASETS, DATALOADERS AND TRANSFORMS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "earuwLSiWvU0",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Reading Annotations (groud truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "6Fgex1RYWuW6",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2019-12-31 16', '2019-12-31 16', '2019-12-31 16', '2019-12-31 16', '2019-12-31 16']\n"
     ]
    }
   ],
   "source": [
    "# specify path to data\n",
    "path2data = 'data/test/'\n",
    "\n",
    "train_gt_data_all = pd.read_csv(path2data + 'sample_output_seomjingang.csv')\n",
    "\n",
    "import datetime\n",
    "from pytz import timezone\n",
    "# get all timestamps\n",
    "gt_timestamps = train_gt_data_all['관측시간']\n",
    "ls = []\n",
    "UTC = timezone('UTC')\n",
    "for i in range(len(gt_timestamps)):\n",
    "    date_time_obj = datetime.datetime.strptime(gt_timestamps[i], '%Y-%m-%d %H').astimezone(UTC)\n",
    "    ls.append(str(date_time_obj)[:13])\n",
    "print(ls[:5])\n",
    "train_gt_data_all['관측시간'] = ls\n",
    "train_gt_data_all.to_csv('temp.csv', index=False)\n",
    "gt_timestamps = train_gt_data_all['관측시간']\n",
    "gt_timestamps = list(dict.fromkeys(gt_timestamps)) # remove duplicates\n",
    "gt_timestamps = [gt_timestamps[i].replace('-', '').replace(' ', '') + '00' for i in range(len(gt_timestamps))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>관측소코드</th>\n",
       "      <th>관측소명</th>\n",
       "      <th>관측시간</th>\n",
       "      <th>시강수량</th>\n",
       "      <th>누가강수량</th>\n",
       "      <th>비고</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4001430</td>\n",
       "      <td>진안군(도통리)</td>\n",
       "      <td>2019-12-31 16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4001440</td>\n",
       "      <td>임실군(용암리)</td>\n",
       "      <td>2019-12-31 16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4001450</td>\n",
       "      <td>순창군(시산리)</td>\n",
       "      <td>2019-12-31 16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4003420</td>\n",
       "      <td>임실군(섬진강댐)</td>\n",
       "      <td>2019-12-31 16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4007450</td>\n",
       "      <td>보성군(복내리)</td>\n",
       "      <td>2019-12-31 16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     관측소코드       관측소명           관측시간  시강수량  누가강수량  비고\n",
       "0  4001430   진안군(도통리)  2019-12-31 16   0.0    0.0 NaN\n",
       "1  4001440   임실군(용암리)  2019-12-31 16   0.0    0.0 NaN\n",
       "2  4001450   순창군(시산리)  2019-12-31 16   0.0    0.0 NaN\n",
       "3  4003420  임실군(섬진강댐)  2019-12-31 16   0.0    0.0 NaN\n",
       "4  4007450   보성군(복내리)  2019-12-31 16   0.0    0.0 NaN"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_gt_data_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "id": "cTsZ0vbchAmq",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Get GPM, RR, TPW\n",
    "import xarray as xr\n",
    "import glob\n",
    "%matplotlib inline\n",
    "\n",
    "filenames_dict = dict() # {timestamp: [list of files]}\n",
    "filenames_val_dict = dict()\n",
    "\n",
    "def filter_by_timestamp(original_list, f_dict):\n",
    "    new_list = []\n",
    "    for timestamp in gt_timestamps:\n",
    "        for i in range(len(original_list)):\n",
    "            if timestamp in original_list[i]:\n",
    "                new_list.append(original_list[i])\n",
    "                if timestamp not in f_dict.keys():\n",
    "                    f_dict[timestamp] = [original_list[i]]\n",
    "                else:\n",
    "                    f_dict[timestamp].append(original_list[i])\n",
    "                break\n",
    "    return new_list\n",
    "\n",
    "def gpm_filter_by_timestamp(original_list, f_dict):\n",
    "    new_list = []\n",
    "    for timestamp in gt_timestamps:\n",
    "        for i in range(len(original_list)):\n",
    "            if timestamp[0:8] in original_list[i] and 'S'+timestamp[8:13] in original_list[i] :\n",
    "                new_list.append(original_list[i])\n",
    "                if timestamp not in f_dict.keys():\n",
    "                    f_dict[timestamp] = [original_list[i]]\n",
    "                else:\n",
    "                    f_dict[timestamp].append(original_list[i])\n",
    "                break\n",
    "    return new_list\n",
    "\n",
    "# Train dataset\n",
    "# GPM\n",
    "#!pip install rasterio\n",
    "gpm_file_list = glob.glob(\"datat/train/input_nasa_gpm/*.tif\")\n",
    "# only retrive files matching the timestamp\n",
    "gpm_file_list = gpm_filter_by_timestamp(gpm_file_list, filenames_dict)\n",
    "#gpm_dset_all = [xr.open_rasterio(gpm_file_list[i]) for i in range(len(gpm_file_list))]\n",
    "#gpm_images = [gpm_dset_all[i].to_dataset('band').rename({1: 'red'}).red.values for i in range(len(gpm_file_list))]\n",
    "\n",
    "# TPW \n",
    "# get all *.nc files\n",
    "valid_max = 10000\n",
    "tpw_file_list = glob.glob(\"datat/train/tpw/*.nc\")\n",
    "tpw_file_list = filter_by_timestamp(tpw_file_list, filenames_dict)\n",
    "\n",
    "#tpw_dset_all = [xr.open_dataset(tpw_file_list[i]) for i in range(len(tpw_file_list))]\n",
    "#tpw_images = [tpw_dset_all[i]['TPW'].values / valid_max for i in range(len(tpw_dset_all))]\n",
    "\n",
    "# RR \n",
    "# get all *.nc files\n",
    "rr_file_list = glob.glob(\"datat/train/rr/*.nc\")\n",
    "rr_file_list = filter_by_timestamp(rr_file_list, filenames_dict)\n",
    "\n",
    "#rr_dset_all = [xr.open_dataset(rr_file_list[i]) for i in range(len(rr_file_list))]\n",
    "#rr_images = [rr_dset_all[i]['RR'].values / valid_max for i in range(len(rr_dset_all))]\n",
    "\n",
    "#train_file_list_only_names = [train_file_list[i][train_file_list[i].find(\"train/\")+6:] for i in range(len(train_file_list))]\n",
    "#print(train_file_list_only_names)\n",
    "\n",
    "# Validation dataset\n",
    "gpm_val_file_list = glob.glob(\"datat/val/input_nasa_gpm/*.tif\")\n",
    "gpm_val_file_list = gpm_filter_by_timestamp(gpm_val_file_list, filenames_val_dict)\n",
    "tpw_val_file_list = glob.glob(\"datat/val/tpw/*.nc\")\n",
    "tpw_val_file_list = filter_by_timestamp(tpw_val_file_list, filenames_val_dict)\n",
    "rr_val_file_list = glob.glob(\"datat/val/rr/*.nc\")\n",
    "rr_val_file_list = filter_by_timestamp(rr_val_file_list, filenames_val_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "id": "1B536hydMTyz",
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Convert to a single image\n",
    "\n",
    "IMG_SIZE  = (224, 224) # image size of efficient net\n",
    "valid_max = 100.\n",
    "scale = 10.\n",
    "\n",
    "def convert2RGB(filenames_dict):\n",
    "    time_image_dict = dict()\n",
    "    train_images = []\n",
    "    for k in filenames_dict.keys():\n",
    "        img_filename_list = filenames_dict[k]\n",
    "        if (len(img_filename_list) == 3):\n",
    "            gpm_img = np.array([])\n",
    "            tpw_img = np.array([])\n",
    "            rr_img = np.array([])\n",
    "            for filename in img_filename_list:\n",
    "                if 'HHR' in filename:\n",
    "                    temp = xr.open_rasterio(filename).to_dataset('band').rename({1: 'red'}).red.values /30000.\n",
    "                    gpm_img = temp.copy()\n",
    "                    gpm_img.resize(IMG_SIZE)\n",
    "                if 'tpw' in filename:\n",
    "                    temp = xr.open_dataset(filename)['TPW'].values / valid_max\n",
    "                    tpw_img = temp.copy()\n",
    "                    tpw_img.resize(IMG_SIZE)\n",
    "                if 'rr' in filename:\n",
    "                    temp = xr.open_dataset(filename)['RR'].values / valid_max\n",
    "                    rr_img = temp.copy()\n",
    "                    rr_img.resize(IMG_SIZE)\n",
    "            #print(\"gpm size: \", gpm_img.shape)\n",
    "            #print(\"tpw size: \", tpw_img.shape)\n",
    "            #print(\"rr size: \", rr_img.shape)\n",
    "            stacked_image = np.dstack((tpw_img, rr_img, gpm_img))\n",
    "            time_image_dict[k] = stacked_image\n",
    "            train_images.append(stacked_image)\n",
    "    return time_image_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Convert to a single image\n",
    "time_image_dict = convert2RGB(filenames_dict)\n",
    "time_image_val_dict = convert2RGB(filenames_val_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Since it is consecutive images, what if we concat four images?\n",
    "# ____\n",
    "#|_|_|\n",
    "#|_|_|\n",
    "print(len(time_image_dict.keys()))\n",
    "print(len(time_image_val_dict.keys()))\n",
    "concatenate_images = False\n",
    "time_image_dict_concat = dict()\n",
    "if (concatenate_images):\n",
    "    new_images = []\n",
    "\n",
    "    for i in range(0, len(train_images)-4):\n",
    "        new_image_row_0 = np.concatenate((train_images[i], train_images[i+1]), axis=0)\n",
    "        new_image_row_1 = np.concatenate((train_images[i+2], train_images[i+3]), axis=0)\n",
    "        new_image = np.concatenate((new_image_row_0, new_image_row_1), axis=1)\n",
    "        new_images.append(new_image)\n",
    "\n",
    "    print(len(train_images), \" vs. \", len(new_images))\n",
    "    \n",
    "    for i, key in enumerate(time_image_dict.keys()):\n",
    "        if (i==len(new_images)): break\n",
    "        time_image_dict_concat[key] = new_images[i]\n",
    "    \n",
    "    time_image_dict = time_image_dict_concat\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u7mVztvoLM8b",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Save converted files to .npy\n",
    "save_as_npy = True\n",
    "if (save_as_npy):\n",
    "    with open(path2data + '/rgb_images.npy', 'wb') as f:\n",
    "        np.save(f, time_image_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gl-kSa88ZE-m",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Data structure is as follows:\n",
    "image_name, 년월일시, 도통리 시강수량, 용암리 시강수량, 시산리 시강수량, 섬진강댐 시강수량, 복내리 시강수량, 주암댐 시강수량, 동가리 시강수량, 맹리 시강수량, 우산리 시강수량, 동복댐 시강수량, 봉동리 시강수량, 보성강댐 시강수량\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0qKa5QQrbzoo",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class SeomjingangDataset(Dataset):\n",
    "    \"\"\"Seomjingang dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, time_image_dict, transform=None):\n",
    "        \"\"\"\n",
    "        Converts csv data into N x 12 (no of observatories) ordered by time with image names added\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            n (int): Number of data entries to use.\n",
    "            image_names (list): List of file names (timestamps) that will be added to the ground truth data\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.train_gt_data_all = pd.read_csv(root_dir + \"/\" + csv_file)\n",
    "        #self.train_gt_data = train_gt_data_all.head(n)\n",
    "        print(\"image_dict length\", len(time_image_dict.keys()))\n",
    "        self.train_data = self.train_gt_data_all.pivot(index=\"관측시간\", columns=\"관측소명\", values=\"시강수량\")\n",
    "        print(\"image_dict length\", len(self.train_data))\n",
    "        self.train_data = self.train_data.head(len(time_image_dict.keys()))\n",
    "        self.train_data.insert(0, \"image_name\", time_image_dict.keys())\n",
    "        self.root_dir = root_dir\n",
    "        self.time_image_dict = time_image_dict\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.train_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        image_name = self.train_data.iloc[idx, 0]\n",
    "        tpw_image = self.time_image_dict[image_name]\n",
    "        tpws = self.train_data.iloc[idx, 1:]\n",
    "        tpws = np.array([tpws])\n",
    "        tpws = tpws.astype('float')\n",
    "        sample = {'image': tpw_image, 'hourly_rainfall': tpws}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "afBs5mmHoM9Z",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "sjg_train_dataset = SeomjingangDataset(csv_file='train_output_seomjingang.csv',\n",
    "                                 root_dir='datat/train/',\n",
    "                                 time_image_dict = time_image_dict)\n",
    "sjg_val_dataset = SeomjingangDataset(csv_file='train_output_seomjingang.csv',\n",
    "                                 root_dir='datat/val/',\n",
    "                                 time_image_dict = time_image_val_dict)\n",
    "\n",
    "# check dataset\n",
    "fig = plt.figure()\n",
    "\n",
    "def show_tpw(image):\n",
    "    \"\"\"Show image tpw\"\"\"\n",
    "    plt.imshow(image)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "\n",
    "for i in range(len(sjg_train_dataset)):\n",
    "    sample = sjg_train_dataset[i]\n",
    "\n",
    "    print(i, sample['image'].shape, sample['hourly_rainfall'].shape)\n",
    "\n",
    "    ax = plt.subplot(1, 4, i + 1)\n",
    "    plt.tight_layout()\n",
    "    ax.set_title('Sample #{}'.format(i))\n",
    "    ax.axis('off')\n",
    "    show_tpw(sample['image'])\n",
    "\n",
    "    if i == 3:\n",
    "        plt.show()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "edZgyw5PsW4j",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Transform image to make it fit to efficientNet\n",
    "class Rescale(object):\n",
    "    \"\"\"Rescale the image in a sample to a given size.\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size. If tuple, output is\n",
    "            matched to output_size. If int, smaller of image edges is matched\n",
    "            to output_size keeping aspect ratio the same.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, tpws = sample['image'], sample['hourly_rainfall']\n",
    "\n",
    "        h, w = image.shape[:2]\n",
    "        if isinstance(self.output_size, int):\n",
    "            if h > w:\n",
    "                new_h, new_w = self.output_size * h / w, self.output_size\n",
    "            else:\n",
    "                new_h, new_w = self.output_size, self.output_size * w / h\n",
    "        else:\n",
    "            new_h, new_w = self.output_size\n",
    "\n",
    "        new_h, new_w = int(new_h), int(new_w)\n",
    "\n",
    "        img = transform.resize(image, (new_h, new_w))\n",
    "\n",
    "        return {'image': img, 'hourly_rainfall': tpws}\n",
    "\n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, tpws = sample['image'], sample['hourly_rainfall']\n",
    "\n",
    "        # swap color axis because\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C x H x W\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        return {'image': torch.from_numpy(image),\n",
    "                'hourly_rainfall': torch.from_numpy(tpws)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nT8rzJ4L_oSl",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "sjg_train_dataset = SeomjingangDataset(csv_file='train_output_seomjingang.csv',\n",
    "                                 root_dir='datat/train/',\n",
    "                                 time_image_dict = time_image_dict,\n",
    "                                 transform=transforms.Compose([\n",
    "                                               Rescale(224),\n",
    "                                               ToTensor()\n",
    "                                           ]))\n",
    "sjg_val_dataset = SeomjingangDataset(csv_file='train_output_seomjingang.csv',\n",
    "                                 root_dir='datat/val/',\n",
    "                                 time_image_dict = time_image_val_dict,\n",
    "                                 transform=transforms.Compose([\n",
    "                                               Rescale(224),\n",
    "                                               ToTensor()\n",
    "                                           ]))\n",
    "\n",
    "for i in range(len(sjg_train_dataset)):\n",
    "    sample = sjg_train_dataset[i]\n",
    "\n",
    "    print(i, sample['image'].size(), sample['hourly_rainfall'].size())\n",
    "\n",
    "    if i == 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U_WPXoAcU8ac",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# data split already by folder # next TODO try setting batch_size to smaller number to account for time relevance\n",
    "# make dataloader\n",
    "train_dl = DataLoader(sjg_train_dataset, batch_size=32, shuffle=True)\n",
    "val_dl = DataLoader(sjg_val_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NSpYOxOH9TVt",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 2. 모델 구축하기\n",
    "코드는 https://github.com/zsef123/EfficientNets-PyTorch/blob/master/models/effnet.py 를 참고했습니다.\n",
    "\n",
    "https://github.com/katsura-jp/efficientnet-pytorch/blob/master/model/efficientnet.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PjJoT-8v9g9P",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Swish activation function\n",
    "class Swish(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x * self.sigmoid(x)\n",
    "\n",
    "# check\n",
    "if __name__ == '__main__':\n",
    "    x = torch.randn(3, 3, 224, 224)\n",
    "    model = Swish()\n",
    "    output = model(x)\n",
    "    print('output size:', output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uixhxPQ6GpT4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# SE Block\n",
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, in_channels, r=4):\n",
    "        super().__init__()\n",
    "\n",
    "        self.squeeze = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.excitation = nn.Sequential(\n",
    "            nn.Linear(in_channels, in_channels * r),\n",
    "            Swish(),\n",
    "            nn.Linear(in_channels * r, in_channels),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.squeeze(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.excitation(x)\n",
    "        x = x.view(x.size(0), x.size(1), 1, 1)\n",
    "        return x\n",
    "\n",
    "# check\n",
    "if __name__ == '__main__':\n",
    "    x = torch.randn(3, 56, 17, 17)\n",
    "    model = SEBlock(x.size(1))\n",
    "    output = model(x)\n",
    "    print('output size:', output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2zq70pzaKVxO",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class MBConv(nn.Module):\n",
    "    expand = 6\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, se_scale=4, p=0.5):\n",
    "        super().__init__()\n",
    "        # first MBConv is not using stochastic depth\n",
    "        self.p = torch.tensor(p).float() if (in_channels == out_channels) else torch.tensor(1).float()\n",
    "\n",
    "        self.residual = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, in_channels * MBConv.expand, 1, stride=stride, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(in_channels * MBConv.expand, momentum=0.99, eps=1e-3),\n",
    "            Swish(),\n",
    "            nn.Conv2d(in_channels * MBConv.expand, in_channels * MBConv.expand, kernel_size=kernel_size,\n",
    "                      stride=1, padding=kernel_size//2, bias=False, groups=in_channels*MBConv.expand),\n",
    "            nn.BatchNorm2d(in_channels * MBConv.expand, momentum=0.99, eps=1e-3),\n",
    "            Swish()\n",
    "        )\n",
    "\n",
    "        self.se = SEBlock(in_channels * MBConv.expand, se_scale)\n",
    "\n",
    "        self.project = nn.Sequential(\n",
    "            nn.Conv2d(in_channels*MBConv.expand, out_channels, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(out_channels, momentum=0.99, eps=1e-3)\n",
    "        )\n",
    "\n",
    "        self.shortcut = (stride == 1) and (in_channels == out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # stochastic depth\n",
    "        if self.training:\n",
    "            if not torch.bernoulli(self.p):\n",
    "                return x\n",
    "\n",
    "        x_shortcut = x\n",
    "        x_residual = self.residual(x)\n",
    "        x_se = self.se(x_residual)\n",
    "\n",
    "        x = x_se * x_residual\n",
    "        x = self.project(x)\n",
    "\n",
    "        if self.shortcut:\n",
    "            x= x_shortcut + x\n",
    "\n",
    "        return x\n",
    "\n",
    "# check\n",
    "if __name__ == '__main__':\n",
    "    x = torch.randn(3, 16, 24, 24)\n",
    "    model = MBConv(x.size(1), x.size(1), 3, stride=1, p=1)\n",
    "    model.train()\n",
    "    output = model(x)\n",
    "    x = (output == x)\n",
    "    print('output size:', output.size(), 'Stochastic depth:', x[1,0,0,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZbmQXf2aZ3FZ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class SepConv(nn.Module):\n",
    "    expand = 1\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, se_scale=4, p=0.5):\n",
    "        super().__init__()\n",
    "        # first SepConv is not using stochastic depth\n",
    "        self.p = torch.tensor(p).float() if (in_channels == out_channels) else torch.tensor(1).float()\n",
    "\n",
    "        self.residual = nn.Sequential(\n",
    "            nn.Conv2d(in_channels * SepConv.expand, in_channels * SepConv.expand, kernel_size=kernel_size,\n",
    "                      stride=1, padding=kernel_size//2, bias=False, groups=in_channels*SepConv.expand),\n",
    "            nn.BatchNorm2d(in_channels * SepConv.expand, momentum=0.99, eps=1e-3),\n",
    "            Swish()\n",
    "        )\n",
    "\n",
    "        self.se = SEBlock(in_channels * SepConv.expand, se_scale)\n",
    "\n",
    "        self.project = nn.Sequential(\n",
    "            nn.Conv2d(in_channels*SepConv.expand, out_channels, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(out_channels, momentum=0.99, eps=1e-3)\n",
    "        )\n",
    "\n",
    "        self.shortcut = (stride == 1) and (in_channels == out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # stochastic depth\n",
    "        if self.training:\n",
    "            if not torch.bernoulli(self.p):\n",
    "                return x\n",
    "\n",
    "        x_shortcut = x\n",
    "        x_residual = self.residual(x)\n",
    "        x_se = self.se(x_residual)\n",
    "\n",
    "        x = x_se * x_residual\n",
    "        x = self.project(x)\n",
    "\n",
    "        if self.shortcut:\n",
    "            x= x_shortcut + x\n",
    "\n",
    "        return x\n",
    "\n",
    "# check\n",
    "if __name__ == '__main__':\n",
    "    x = torch.randn(3, 16, 24, 24)\n",
    "    model = SepConv(x.size(1), x.size(1), 3, stride=1, p=1)\n",
    "    model.train()\n",
    "    output = model(x)\n",
    "    # stochastic depth check\n",
    "    x = (output == x)\n",
    "    print('output size:', output.size(), 'Stochastic depth:', x[1,0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JxPq3eBKGGRM",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class EfficientNet(nn.Module):\n",
    "    def __init__(self, num_classes=10, width_coef=1., depth_coef=1., scale=1., dropout=0.2, se_scale=4, stochastic_depth=False, p=0.5):\n",
    "        super().__init__()\n",
    "        channels = [32, 16, 24, 40, 80, 112, 192, 320, 1280]\n",
    "        repeats = [1, 2, 2, 3, 3, 4, 1]\n",
    "        strides = [1, 2, 2, 2, 1, 2, 1]\n",
    "        kernel_size = [3, 3, 5, 3, 5, 5, 3]\n",
    "        depth = depth_coef\n",
    "        width = width_coef\n",
    "\n",
    "        channels = [int(x*width) for x in channels]\n",
    "        repeats = [int(x*depth) for x in repeats]\n",
    "\n",
    "        # stochastic depth\n",
    "        if stochastic_depth:\n",
    "            self.p = p\n",
    "            self.step = (1 - 0.5) / (sum(repeats) - 1)\n",
    "        else:\n",
    "            self.p = 1\n",
    "            self.step = 0\n",
    "\n",
    "\n",
    "        # efficient net\n",
    "        self.upsample = nn.Upsample(scale_factor=scale, mode='bilinear', align_corners=False)\n",
    "\n",
    "        self.stage1 = nn.Sequential(\n",
    "            nn.Conv2d(3, channels[0],3, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(channels[0], momentum=0.99, eps=1e-3)\n",
    "        )\n",
    "\n",
    "        self.stage2 = self._make_Block(SepConv, repeats[0], channels[0], channels[1], kernel_size[0], strides[0], se_scale)\n",
    "\n",
    "        self.stage3 = self._make_Block(MBConv, repeats[1], channels[1], channels[2], kernel_size[1], strides[1], se_scale)\n",
    "\n",
    "        self.stage4 = self._make_Block(MBConv, repeats[2], channels[2], channels[3], kernel_size[2], strides[2], se_scale)\n",
    "\n",
    "        self.stage5 = self._make_Block(MBConv, repeats[3], channels[3], channels[4], kernel_size[3], strides[3], se_scale)\n",
    "\n",
    "        self.stage6 = self._make_Block(MBConv, repeats[4], channels[4], channels[5], kernel_size[4], strides[4], se_scale)\n",
    "\n",
    "        self.stage7 = self._make_Block(MBConv, repeats[5], channels[5], channels[6], kernel_size[5], strides[5], se_scale)\n",
    "\n",
    "        self.stage8 = self._make_Block(MBConv, repeats[6], channels[6], channels[7], kernel_size[6], strides[6], se_scale)\n",
    "\n",
    "        self.stage9 = nn.Sequential(\n",
    "            nn.Conv2d(channels[7], channels[8], 1, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(channels[8], momentum=0.99, eps=1e-3),\n",
    "            Swish()\n",
    "        ) \n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        #self.linear = nn.Linear(channels[8], num_classes) # TODO: change here to 1?\n",
    "        self.linear = nn.Linear(channels[8], 12)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.upsample(x)\n",
    "        x = self.stage1(x)\n",
    "        x = self.stage2(x)\n",
    "        x = self.stage3(x)\n",
    "        x = self.stage4(x)\n",
    "        x = self.stage5(x)\n",
    "        x = self.stage6(x)\n",
    "        x = self.stage7(x)\n",
    "        x = self.stage8(x)\n",
    "        x = self.stage9(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "    def _make_Block(self, block, repeats, in_channels, out_channels, kernel_size, stride, se_scale):\n",
    "        strides = [stride] + [1] * (repeats - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(in_channels, out_channels, kernel_size, stride, se_scale, self.p))\n",
    "            in_channels = out_channels\n",
    "            self.p -= self.step\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "def efficientnet_b0(num_classes=10):\n",
    "    return EfficientNet(num_classes=num_classes, width_coef=1.0, depth_coef=1.0, scale=1.0,dropout=0.2, se_scale=4)\n",
    "\n",
    "def efficientnet_b1(num_classes=10):\n",
    "    return EfficientNet(num_classes=num_classes, width_coef=1.0, depth_coef=1.1, scale=240/224, dropout=0.2, se_scale=4)\n",
    "\n",
    "def efficientnet_b2(num_classes=10):\n",
    "    return EfficientNet(num_classes=num_classes, width_coef=1.1, depth_coef=1.2, scale=260/224., dropout=0.3, se_scale=4)\n",
    "\n",
    "def efficientnet_b3(num_classes=10):\n",
    "    return EfficientNet(num_classes=num_classes, width_coef=1.2, depth_coef=1.4, scale=300/224, dropout=0.3, se_scale=4)\n",
    "\n",
    "def efficientnet_b4(num_classes=10):\n",
    "    return EfficientNet(num_classes=num_classes, width_coef=1.4, depth_coef=1.8, scale=380/224, dropout=0.4, se_scale=4)\n",
    "\n",
    "def efficientnet_b5(num_classes=10):\n",
    "    return EfficientNet(num_classes=num_classes, width_coef=1.6, depth_coef=2.2, scale=456/224, dropout=0.4, se_scale=4)\n",
    "\n",
    "def efficientnet_b6(num_classes=10):\n",
    "    return EfficientNet(num_classes=num_classes, width_coef=1.8, depth_coef=2.6, scale=528/224, dropout=0.5, se_scale=4)\n",
    "\n",
    "def efficientnet_b7(num_classes=10):\n",
    "    return EfficientNet(num_classes=num_classes, width_coef=2.0, depth_coef=3.1, scale=600/224, dropout=0.5, se_scale=4)\n",
    "\n",
    "\n",
    "# check\n",
    "if __name__ == '__main__':\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    x = torch.randn(3, 3, 224, 224).to(device)\n",
    "    model = efficientnet_b0().to(device)\n",
    "    output = model(x)\n",
    "    print('output size:', output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a1X1ZICfetfq",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# print model summary\n",
    "model = efficientnet_b0().to(device)\n",
    "#summary(model, (3,224,224), device=device.type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DYiTiNkJwS5p",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 3. 학습하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eUmVhxGImFsX",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# define loss function, optimizer, lr_scheduler\n",
    "loss_func = nn.CrossEntropyLoss(reduction='sum')\n",
    "#loss_func = nn.MSELoss(reduction='mean')\n",
    "opt = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "lr_scheduler = ReduceLROnPlateau(opt, mode='min', factor=0.1, patience=10)\n",
    "\n",
    "\n",
    "# get current lr\n",
    "def get_lr(opt):\n",
    "    for param_group in opt.param_groups:\n",
    "        return param_group['lr']\n",
    "\n",
    "# this metric is for classification!\n",
    "# calculate the metric per mini-batch\n",
    "def metric_batch(output, target):\n",
    "    # original function returns number of correct classification\n",
    "    # by doing so, measures accuracy\n",
    "    # instead, calculate how close each value is to target value,\n",
    "    # check whether it is within some threshold\n",
    "    # and count number of items within the threshold\n",
    "    # threshold: parameter to fine-tune\n",
    "    correct_threshold = 0.01; #TODO change this?\n",
    "    \n",
    "    diff = abs(output - target)\n",
    "    corrects = torch.count_nonzero(diff.le(correct_threshold)).item()\n",
    "    #pred = output.argmax(1, keepdim=True) # index of max value in output\n",
    "    #corrects = pred.eq(target.view_as(pred)).sum().item()\n",
    "    return corrects\n",
    "\n",
    "\n",
    "# calculate the loss per mini-batch\n",
    "def loss_batch(loss_func, output, target, opt=None):\n",
    "    loss_b = loss_func(output, target).float()\n",
    "    metric_b = metric_batch(output, target)\n",
    "\n",
    "    if opt is not None:\n",
    "        opt.zero_grad()\n",
    "        loss_b.backward()\n",
    "        opt.step()\n",
    "    \n",
    "    return loss_b.item(), metric_b\n",
    "\n",
    "\n",
    "# calculate the loss per epochs\n",
    "def loss_epoch(model, loss_func, dataset_dl, sanity_check=False, opt=None):\n",
    "    running_loss = 0.0\n",
    "    running_metric = 0.0\n",
    "    len_data = len(dataset_dl.dataset)\n",
    "\n",
    "    for index, val in enumerate(dataset_dl):\n",
    "        xb = val['image'].float()\n",
    "        yb = torch.squeeze(val['hourly_rainfall']).float()\n",
    "        xb = xb.to(device)\n",
    "        yb = yb.to(device)\n",
    "        output = model(xb).float()\n",
    "        if (index % 1000 == 0): \n",
    "            print(\"output: \", output)\n",
    "            print(\"target: \", yb)\n",
    "        assert(output.shape == yb.shape, \"shapes do not match!\")\n",
    "\n",
    "        loss_b, metric_b = loss_batch(loss_func, output, yb, opt)\n",
    "\n",
    "        running_loss += loss_b\n",
    "        \n",
    "        if metric_b is not None:\n",
    "            running_metric += metric_b\n",
    "\n",
    "        if sanity_check is True:\n",
    "            break\n",
    "\n",
    "    loss = running_loss / len_data\n",
    "    metric = running_metric / len_data\n",
    "    return loss, metric\n",
    "\n",
    "\n",
    "# function to start training\n",
    "def train_val(model, params):\n",
    "    num_epochs=params['num_epochs']\n",
    "    loss_func=params['loss_func']\n",
    "    opt=params['optimizer']\n",
    "    train_dl=params['train_dl']\n",
    "    val_dl=params['val_dl']\n",
    "    sanity_check=params['sanity_check']\n",
    "    lr_scheduler=params['lr_scheduler']\n",
    "    path2weights=params['path2weights']\n",
    "\n",
    "    loss_history = {'train': [], 'val': []}\n",
    "    metric_history = {'train': [], 'val': []}\n",
    "\n",
    "    best_loss = float('inf')\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        current_lr = get_lr(opt)\n",
    "        print('Epoch {}/{}, current lr= {}'.format(epoch, num_epochs-1, current_lr))\n",
    "\n",
    "        model.train()\n",
    "        train_loss, train_metric = loss_epoch(model, loss_func, train_dl, sanity_check, opt)\n",
    "        loss_history['train'].append(train_loss)\n",
    "        metric_history['train'].append(train_metric)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss, val_metric = loss_epoch(model, loss_func, val_dl, sanity_check)\n",
    "        loss_history['val'].append(val_loss)\n",
    "        metric_history['val'].append(val_metric)\n",
    "\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            torch.save(model.state_dict(), path2weights)\n",
    "            print('Copied best model weights!')\n",
    "\n",
    "        lr_scheduler.step(val_loss)\n",
    "        if current_lr != get_lr(opt):\n",
    "            print('Loading best model weights!')\n",
    "            model.load_state_dict(best_model_wts)\n",
    "\n",
    "        print('train loss: %.6f, val loss: %.6f, accuracy: %.2f, time: %.4f min' %(train_loss, val_loss, 100*val_metric, (time.time()-start_time)/60))\n",
    "        print('-'*10)\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, loss_history, metric_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IsuU2EiLwZVz",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# define the training parameters\n",
    "params_train = {\n",
    "    'num_epochs':100,\n",
    "    'optimizer':opt,\n",
    "    'loss_func':loss_func,\n",
    "    'train_dl':train_dl,\n",
    "    'val_dl':val_dl,\n",
    "    'sanity_check':False,\n",
    "    'lr_scheduler':lr_scheduler,\n",
    "    'path2weights':'./models/weights.pt',\n",
    "}\n",
    "\n",
    "# check the directory to save weights.pt\n",
    "def createFolder(directory):\n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    except OSerror:\n",
    "        print('Error')\n",
    "createFolder('./models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3yS8vS_wwbUG",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model, loss_hist, metric_hist = train_val(model, params_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3v79XI6YxG_U",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "num_epochs = params_train['num_epochs']\n",
    "\n",
    "# Plot train-val loss\n",
    "plt.title('Train-Val Loss')\n",
    "plt.plot(range(1, num_epochs+1), loss_hist['train'], label='train')\n",
    "plt.plot(range(1, num_epochs+1), loss_hist['val'], label='val')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Training Epochs')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# plot train-val accuracy\n",
    "plt.title('Train-Val Accuracy')\n",
    "plt.plot(range(1, num_epochs+1), metric_hist['train'], label='train')\n",
    "plt.plot(range(1, num_epochs+1), metric_hist['val'], label='val')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Training Epochs')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ai-challenge.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/Seonghoon-Yu/Paper_Review_and_Implementation_in_PyTorch/blob/master/Classification/EfficientNet(2019).ipynb",
     "timestamp": 1636552164457
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}